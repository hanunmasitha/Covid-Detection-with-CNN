{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "dPboxbYnRCKu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Requirement already satisfied: tensorflow in c:\\users\\hanun\\venv\\lib\\site-packages (2.4.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in c:\\users\\hanun\\venv\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in c:\\users\\hanun\\venv\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: gast==0.3.3 in c:\\users\\hanun\\venv\\lib\\site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0rc0 in c:\\users\\hanun\\venv\\lib\\site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in c:\\users\\hanun\\venv\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\hanun\\venv\\lib\\site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: absl-py~=0.10 in c:\\users\\hanun\\venv\\lib\\site-packages (from tensorflow) (0.11.0)\n",
      "Requirement already satisfied: h5py~=2.10.0 in c:\\users\\hanun\\venv\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in c:\\users\\hanun\\venv\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\hanun\\venv\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\hanun\\venv\\lib\\site-packages (from tensorflow) (0.36.2)\n",
      "Requirement already satisfied: numpy~=1.19.2 in c:\\users\\hanun\\venv\\lib\\site-packages (from tensorflow) (1.19.5)\n",
      "Requirement already satisfied: grpcio~=1.32.0 in c:\\users\\hanun\\venv\\lib\\site-packages (from tensorflow) (1.32.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.3.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\hanun\\venv\\scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\hanun\\venv\\lib\\site-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in c:\\users\\hanun\\venv\\lib\\site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in c:\\users\\hanun\\venv\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: tensorboard~=2.4 in c:\\users\\hanun\\venv\\lib\\site-packages (from tensorflow) (2.4.1)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\hanun\\venv\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\hanun\\venv\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\hanun\\venv\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (3.3.3)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\hanun\\venv\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (1.7.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\hanun\\venv\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (1.24.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\hanun\\venv\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (0.4.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\hanun\\venv\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (2.25.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\hanun\\venv\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (51.3.3)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\hanun\\venv\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\hanun\\venv\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\hanun\\venv\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.7)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\hanun\\venv\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\hanun\\venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hanun\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\hanun\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hanun\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.26.2)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\hanun\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.10)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\hanun\\venv\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: keras in c:\\users\\hanun\\venv\\lib\\site-packages (2.4.3)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\hanun\\venv\\lib\\site-packages (from keras) (1.19.5)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\hanun\\venv\\lib\\site-packages (from keras) (5.3.1)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\hanun\\venv\\lib\\site-packages (from keras) (1.6.0)\n",
      "Requirement already satisfied: h5py in c:\\users\\hanun\\venv\\lib\\site-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: six in c:\\users\\hanun\\venv\\lib\\site-packages (from h5py->keras) (1.15.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.3.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\hanun\\venv\\scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-gpu\n",
    "!pip install tensorflow\n",
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "mpykjDboRcaq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import random\n",
    "import warnings\n",
    "import os\n",
    "import shutil\n",
    "from PIL import ImageFile\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xD4Cnty5TqyU"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iDTg26aVTy4H"
   },
   "outputs": [],
   "source": [
    "base_dir = 'E:\\Koding\\Python\\Kuliah\\S2\\AI\\Projek\\Dataset'\n",
    "\n",
    "training_dir = os.path.join(base_dir, 'Training')\n",
    "test_dir = os.path.join(base_dir, 'Testing')\n",
    "validation_dir = os.path.join(base_dir, 'Validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MCXcbKnUZPm9"
   },
   "outputs": [],
   "source": [
    "sourceFiles = []\n",
    "classLabels = ['Pneumonia', 'Covid', 'Normal']\n",
    "picture_size = (128, 128)\n",
    "batch_size = 32\n",
    "epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XfgS8JpQZVsP"
   },
   "outputs": [],
   "source": [
    "def transferBetweenFolders(source, dest, splitRate):\n",
    "    global sourceFiles\n",
    "    sourceFiles = os.listdir(source)\n",
    "    if (len(sourceFiles) != 0):\n",
    "        transferFileNumbers = int(len(sourceFiles) * splitRate)\n",
    "        transferIndex = random.sample(range(0, len(sourceFiles)), transferFileNumbers)\n",
    "        for eachIndex in transferIndex:\n",
    "            shutil.move(source + str(sourceFiles[eachIndex]), dest + str(sourceFiles[eachIndex]))\n",
    "    else:\n",
    "        print(\"No file moved. Source empty!\")\n",
    "\n",
    "\n",
    "def transferAllClassBetweenFolders(source, dest, splitRate):\n",
    "    for label in classLabels:\n",
    "        transferBetweenFolders(base_dir + '/' + source + '/' + label + '/',\n",
    "                                base_dir + '/' + dest + '/' + label + '/',\n",
    "                               splitRate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q7yRfHt1ZZIw"
   },
   "outputs": [],
   "source": [
    "# First, check if test folder is empty or not, if not transfer all existing files to train\n",
    "transferAllClassBetweenFolders('Testing', 'Training', 1.0)\n",
    "transferAllClassBetweenFolders('Validation', 'Training', 1.0)\n",
    "# Now, split some part of train data into the test folders.\n",
    "transferAllClassBetweenFolders('Training', 'Testing', 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bstcu2JcZo6c"
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "\n",
    "def prepareNameWithLabels(folderName):\n",
    "    sourceFiles = os.listdir(base_dir + '/Training/' + folderName)\n",
    "    for val in sourceFiles:\n",
    "         X.append(val)\n",
    "         if (folderName == classLabels[0]):\n",
    "             Y.append(0)\n",
    "         elif (folderName == classLabels[1]):\n",
    "             Y.append(1)\n",
    "         else:\n",
    "             Y.append(2)\n",
    "             \n",
    "# Organize file names and class labels in X and Y variables\n",
    "for i in range(len(classLabels)):\n",
    "    prepareNameWithLabels(classLabels[i])\n",
    "\n",
    "X = np.asarray(X)\n",
    "Y = np.asarray(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-HCiVrPHUe5F"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kOUaH8rRcLSH"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "# from keras.utils import plot_model\n",
    "from keras.initializers import glorot_uniform\n",
    "import scipy.misc\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "K.set_learning_phase(1)\n",
    "\n",
    "def identity_block(X, activation, f, filters, stage, block):\n",
    "    \"\"\"\n",
    "    Implementation of the identity block as defined in Figure 3\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    stage -- integer, used to name the layers, depending on their position in the network\n",
    "    block -- string/character, used to name the layers, depending on their position in the network\n",
    "    \n",
    "    Returns:\n",
    "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value. You'll need this later to add back to the main path. \n",
    "    X_shortcut = X\n",
    "    \n",
    "    # First component of main path\n",
    "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', \n",
    "               name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Activation(activation)(X)\n",
    "\n",
    "    \n",
    "    # Second component of main path (≈3 lines)\n",
    "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', \n",
    "               name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
    "    X = Activation(activation)(X)\n",
    "\n",
    "    # Third component of main path (≈2 lines)\n",
    "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', \n",
    "               name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation(activation)(X)\n",
    "    \n",
    "    \n",
    "    return X\n",
    "\n",
    "def convolutional_block(X, activation, f, filters, stage, block, s = 2):\n",
    "    \"\"\"\n",
    "    Implementation of the convolutional block as defined in Figure 4\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    stage -- integer, used to name the layers, depending on their position in the network\n",
    "    block -- string/character, used to name the layers, depending on their position in the network\n",
    "    s -- Integer, specifying the stride to be used\n",
    "    \n",
    "    Returns:\n",
    "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value\n",
    "    X_shortcut = X\n",
    "\n",
    "\n",
    "    ##### MAIN PATH #####\n",
    "    # First component of main path \n",
    "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a', \n",
    "               kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Activation(activation)(X)\n",
    "\n",
    "    # Second component of main path (≈3 lines)\n",
    "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', \n",
    "               name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
    "    X = Activation(activation)(X)\n",
    "\n",
    "\n",
    "    # Third component of main path (≈2 lines)\n",
    "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', \n",
    "               name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
    "\n",
    "\n",
    "    ##### SHORTCUT PATH #### (≈2 lines)\n",
    "    X_shortcut = Conv2D(filters = F3, kernel_size = (1, 1), strides = (s,s), \n",
    "                        padding = 'valid', name = conv_name_base + '1',\n",
    "                        kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation(activation)(X)\n",
    "    \n",
    "    \n",
    "    return X\n",
    "\n",
    "def ResNet50(input_shape=(*picture_size, 3), classes = len(classLabels)):\n",
    "    \"\"\"\n",
    "    Implementation of the popular ResNet50 the following architecture:\n",
    "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
    "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
    "\n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "    classes -- integer, number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "\n",
    "    # Activation Function\n",
    "    activation = 'relu'\n",
    "\n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "\n",
    "    # Stage 1\n",
    "    X = Conv2D(64, (7, 7), strides=(2, 2), name='conv1', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name='bn_conv1')(X)\n",
    "    X = Activation(activation)(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # Stage 2\n",
    "    X = convolutional_block(X, activation, f=3, filters=[64, 64, 256], stage=2, block='a', s=1)\n",
    "    X = identity_block(X, activation, 3, [64, 64, 256], stage=2, block='b')\n",
    "    X = identity_block(X, activation, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # Stage 3 (≈4 lines)\n",
    "    X = convolutional_block(X, activation, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n",
    "    X = identity_block(X, activation, 3, [128, 128, 512], stage=3, block='b')\n",
    "    X = identity_block(X, activation, 3, [128, 128, 512], stage=3, block='c')\n",
    "    X = identity_block(X, activation, 3, [128, 128, 512], stage=3, block='d')\n",
    "\n",
    "    # Stage 4 (≈6 lines)\n",
    "    X = convolutional_block(X, activation, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n",
    "    X = identity_block(X, activation, 3, [256, 256, 1024], stage=4, block='b')\n",
    "    X = identity_block(X, activation, 3, [256, 256, 1024], stage=4, block='c')\n",
    "    X = identity_block(X, activation, 3, [256, 256, 1024], stage=4, block='d')\n",
    "    X = identity_block(X, activation, 3, [256, 256, 1024], stage=4, block='e')\n",
    "    X = identity_block(X, activation, 3, [256, 256, 1024], stage=4, block='f')\n",
    "\n",
    "    # Stage 5 (≈3 lines)\n",
    "    X = convolutional_block(X, activation, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n",
    "    X = identity_block(X, activation, 3, [512, 512, 2048], stage=5, block='b')\n",
    "    X = identity_block(X, activation, 3, [512, 512, 2048], stage=5, block='c')\n",
    "\n",
    "    # AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
    "    X = AveragePooling2D((2,2), name=\"avg_pool\")(X)\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='softmax', name='fc' + str(classes), \n",
    "              kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    \n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
    "\n",
    "    learning_rate = 0.01\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    losses = 'categorical_crossentropy'\n",
    "    model.compile(optimizer=optimizer, loss=losses, metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2FJ-8sPUcuU_"
   },
   "outputs": [],
   "source": [
    "cnn = ResNet50(input_shape = (*picture_size, 3), classes = len(classLabels))\n",
    "cnn.summary()\n",
    "\n",
    "filepath = 'Resnet.h5'\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss',\n",
    "                                                 verbose=1, save_weights_only=False,\n",
    "                                                 save_best_only=True, mode='min')\n",
    "\n",
    "logdir = os.path.join(base_dir, 'logs/mobilenet')\n",
    "tfboard = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "callbacks_list = [checkpoint, tfboard]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n2DhbhkNcz3W"
   },
   "outputs": [],
   "source": [
    "# ===============Stratified K-Fold======================\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "skf.get_n_splits(X, Y)\n",
    "foldNum=0\n",
    "for train_index, val_index in skf.split(X, Y):\n",
    "    #First cut all images from validation to train (if any exists)\n",
    "    transferAllClassBetweenFolders('Validation', 'Training', 1.0)\n",
    "    foldNum+=1\n",
    "    print(\"Results for fold\",foldNum)\n",
    "\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    Y_train, Y_val = Y[train_index], Y[val_index]\n",
    "    # Move validation images of this fold from train folder to the validation folder\n",
    "    for eachIndex in range(len(X_val)):\n",
    "        classLabel=''\n",
    "        if(Y_val[eachIndex]==0):\n",
    "            classLabel=classLabels[0]\n",
    "        elif(Y_val[eachIndex]==1):\n",
    "            classLabel=classLabels[1]\n",
    "        else:\n",
    "            classLabel=classLabels[2]\n",
    "        #Then, copy the validation images to the validation folder\n",
    "        shutil.move(base_dir+'/Training/'+classLabel+'/'+X_val[eachIndex],\n",
    "                    base_dir+'/Validation/'+classLabel+'/'+X_val[eachIndex])\n",
    "\n",
    "    picture_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1. / 255,\n",
    "                                           shear_range=0.2,\n",
    "                                           zoom_range=0.2,\n",
    "                                           horizontal_flip=True)\n",
    "    \n",
    "    training_set = picture_datagen.flow_from_directory(training_dir,\n",
    "                                                       shuffle=True,\n",
    "                                                       target_size=picture_size,\n",
    "                                                       batch_size=batch_size,\n",
    "                                                       class_mode='categorical')\n",
    "\n",
    "    # Preprocessing the Test set\n",
    "    test_set = picture_datagen.flow_from_directory(validation_dir,\n",
    "                                                   shuffle=True,\n",
    "                                                   target_size=picture_size,\n",
    "                                                   batch_size=batch_size,\n",
    "                                                   class_mode='categorical')\n",
    "\n",
    "\n",
    "    # Training the CNN on the Training set and evaluating it on the Test set\n",
    "    fit = cnn.fit(training_set,\n",
    "                    epochs=epoch,\n",
    "                    validation_data=test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qa-MHjHjdWP6"
   },
   "outputs": [],
   "source": [
    "modelpath = base_dir + filepath\n",
    "cnn.save(modelpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ujsIBZdughfY"
   },
   "outputs": [],
   "source": [
    "# menghitung akurasi dari training data\n",
    "\n",
    "picture_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1. / 255,\n",
    "                                           shear_range=0.2,\n",
    "                                           zoom_range=0.2,\n",
    "                                           horizontal_flip=True)\n",
    "    \n",
    "training_set = picture_datagen.flow_from_directory(test_dir,\n",
    "                                                       shuffle=True,\n",
    "                                                       target_size=picture_size,\n",
    "                                                       batch_size=batch_size,\n",
    "                                                       class_mode='categorical')\n",
    "score = cnn.evaluate(training_set)\n",
    "\n",
    "print('Loss: {:0.2f}%'.format(score[0] * 100))\n",
    "print('Accuracy: {:0.2f}%'.format(score[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b6IYritOvmak"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Covid Detection with resnet.ipynb",
   "private_outputs": true,
   "provenance": [
    {
     "file_id": "1mjRqYK1_6fl95qfB8du-SGYdTsXj5KQ_",
     "timestamp": 1637064043070
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
