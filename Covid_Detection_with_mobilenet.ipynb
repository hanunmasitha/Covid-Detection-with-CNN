{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dPboxbYnRCKu",
    "outputId": "177a28cb-7ab0-4138-a07a-c7c60bc27070"
   },
   "outputs": [],
   "source": [
    "#!pip install tensorflow-gpu\n",
    "#!pip install tensorflow\n",
    "#!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "mpykjDboRcaq",
    "outputId": "1c2b7fbc-ce13-4afe-aba4-7588883db8d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.0'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import random\n",
    "import warnings\n",
    "import os\n",
    "import shutil\n",
    "from PIL import ImageFile\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "iDTg26aVTy4H"
   },
   "outputs": [],
   "source": [
    "base_dir = r\"E:\\Koding\\Python\\Kuliah\\S2\\AI\\Projek\\Dataset\"\n",
    "\n",
    "training_dir = os.path.join(base_dir, 'Training')\n",
    "test_dir = os.path.join(base_dir, 'Testing')\n",
    "validation_dir = os.path.join(base_dir, 'Validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "MCXcbKnUZPm9"
   },
   "outputs": [],
   "source": [
    "sourceFiles = []\n",
    "classLabels = ['Pneumonia', 'Covid', 'Normal']\n",
    "picture_size = (224, 224)\n",
    "batch_size = 32\n",
    "epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "XfgS8JpQZVsP"
   },
   "outputs": [],
   "source": [
    "def transferBetweenFolders(source, dest, splitRate):\n",
    "    global sourceFiles\n",
    "    sourceFiles = os.listdir(source)\n",
    "    if (len(sourceFiles) != 0):\n",
    "        transferFileNumbers = int(len(sourceFiles) * splitRate)\n",
    "        transferIndex = random.sample(range(0, len(sourceFiles)), transferFileNumbers)\n",
    "        for eachIndex in transferIndex:\n",
    "            shutil.move(source + str(sourceFiles[eachIndex]), dest + str(sourceFiles[eachIndex]))\n",
    "    else:\n",
    "        print(\"No file moved. Source empty!\")\n",
    "\n",
    "\n",
    "def transferAllClassBetweenFolders(source, dest, splitRate):\n",
    "    for label in classLabels:\n",
    "        transferBetweenFolders(base_dir + '/' + source + '/' + label + '/',\n",
    "                                base_dir + '/' + dest + '/' + label + '/',\n",
    "                               splitRate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "q7yRfHt1ZZIw",
    "outputId": "7c55219a-dedb-4c48-edd3-d115968849d3"
   },
   "outputs": [],
   "source": [
    "# First, check if test folder is empty or not, if not transfer all existing files to train\n",
    "transferAllClassBetweenFolders('Testing', 'Training', 1.0)\n",
    "transferAllClassBetweenFolders('Validation', 'Training', 1.0)\n",
    "# Now, split some part of train data into the test folders.\n",
    "transferAllClassBetweenFolders('Training', 'Testing', 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Bstcu2JcZo6c"
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "\n",
    "def prepareNameWithLabels(folderName):\n",
    "    sourceFiles = os.listdir(base_dir + '/Training/' + folderName)\n",
    "    for val in sourceFiles:\n",
    "        X.append(val)\n",
    "        if (folderName == classLabels[0]):\n",
    "            Y.append(0)\n",
    "        elif (folderName == classLabels[1]):\n",
    "            Y.append(1)\n",
    "        else:\n",
    "            Y.append(2)\n",
    "             \n",
    "# Organize file names and class labels in X and Y variables\n",
    "for i in range(len(classLabels)):\n",
    "    prepareNameWithLabels(classLabels[i])\n",
    "\n",
    "X = np.asarray(X)\n",
    "Y = np.asarray(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-HCiVrPHUe5F"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "kOUaH8rRcLSH"
   },
   "outputs": [],
   "source": [
    "def mobilenetv2():\n",
    "    base_model = keras.applications.mobilenet_v2.MobileNetV2(include_top=False,\n",
    "                                                               weights='imagenet',\n",
    "                                                             input_shape=(224,224,3))\n",
    "\n",
    "    base_model.trainable = False\n",
    "    kernel_regulation = keras.regularizers.l2(0.0001)\n",
    "\n",
    "    x = base_model.output\n",
    "    # Add some new Fully connected layers to\n",
    "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = keras.layers.Flatten()(x)\n",
    "\n",
    "    x = keras.layers.Dense(1024, kernel_regularizer=kernel_regulation, activation='relu')(x)\n",
    "    x = keras.layers.Dropout(0.5)(x)\n",
    "    x = keras.layers.Dense(256, kernel_regularizer=kernel_regulation, activation='relu')(x)\n",
    "    x = keras.layers.Dense(64, kernel_regularizer=kernel_regulation, activation='relu')(x)\n",
    "\n",
    "    output_layer = keras.layers.Dense(3, activation='softmax')(x)\n",
    "\n",
    "    model = keras.models.Model(inputs=base_model.input,outputs=output_layer)\n",
    "\n",
    "    for layer in model.layers[:90]:\n",
    "        layer.trainable=False\n",
    "    for layer in model.layers[90:]:\n",
    "        layer.trainable=True\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    learning_rate = 0.1\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    losses = 'categorical_crossentropy'\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=losses, metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2FJ-8sPUcuU_",
    "outputId": "4afdcfab-fc6d-4f7b-c931-f76f6d25c00c"
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (truncated file: eof = 40960, sblock->base_addr = 0, stored_eof = 9406464)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-c8101b13d898>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcnn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmobilenetv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfilepath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'mobilenetv2.h5'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss',\n\u001b[0;32m      5\u001b[0m                                                  \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_weights_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-aee452ee2d1f>\u001b[0m in \u001b[0;36mmobilenetv2\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmobilenetv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     base_model = keras.applications.mobilenet_v2.MobileNetV2(include_top=False,\n\u001b[0m\u001b[0;32m      3\u001b[0m                                                                \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'imagenet'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                                                              input_shape=(224,224,3))\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hanun\\venv\\lib\\site-packages\\keras\\applications\\mobilenet_v2.py\u001b[0m in \u001b[0;36mMobileNetV2\u001b[1;34m(input_shape, alpha, include_top, weights, input_tensor, pooling, classes, classifier_activation, **kwargs)\u001b[0m\n\u001b[0;32m    422\u001b[0m       weights_path = data_utils.get_file(\n\u001b[0;32m    423\u001b[0m           model_name, weight_path, cache_subdir='models')\n\u001b[1;32m--> 424\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    425\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[0mweights\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hanun\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hanun\\venv\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[0;32m    404\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Driver must be 'fileobj' for file-like object if specified.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m                 \u001b[0mdriver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'fileobj'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 406\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'fileobj'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    407\u001b[0m                     raise ValueError(\"Invalid value of 'fileobj' argument; \"\n\u001b[0;32m    408\u001b[0m                                      \"must equal to file-like object if specified.\")\n",
      "\u001b[1;32mc:\\users\\hanun\\venv\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    171\u001b[0m     \"\"\" Get a new FileID by opening or creating a file.\n\u001b[0;32m    172\u001b[0m     Also validates mode argument.\"\"\"\n\u001b[1;32m--> 173\u001b[1;33m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0muserblock_size\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r+'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to open file (truncated file: eof = 40960, sblock->base_addr = 0, stored_eof = 9406464)"
     ]
    }
   ],
   "source": [
    "cnn = mobilenetv2()\n",
    "\n",
    "filepath = 'mobilenetv2.h5'\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss',\n",
    "                                                 verbose=1, save_weights_only=False,\n",
    "                                                 save_best_only=True, mode='min')\n",
    "\n",
    "logdir = os.path.join(base_dir, 'logs/')\n",
    "tfboard = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "callbacks_list = [checkpoint, tfboard]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n2DhbhkNcz3W",
    "outputId": "e0a7f16e-b0d3-4960-a2aa-063433ead7e2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ===============Stratified K-Fold======================\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "skf.get_n_splits(X, Y)\n",
    "foldNum=0\n",
    "history_loss = []\n",
    "history_acc = []\n",
    "history_val_loss = []\n",
    "history_val_acc = []\n",
    "for train_index, val_index in skf.split(X, Y):\n",
    "    #First cut all images from validation to train (if any exists)\n",
    "    transferAllClassBetweenFolders('Validation', 'Training', 1.0)\n",
    "    foldNum+=1\n",
    "    print(\"Results for fold\",foldNum)\n",
    "\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    Y_train, Y_val = Y[train_index], Y[val_index]\n",
    "    # Move validation images of this fold from train folder to the validation folder\n",
    "    for eachIndex in range(len(X_val)):\n",
    "        classLabel=''\n",
    "        if(Y_val[eachIndex]==0):\n",
    "            classLabel=classLabels[0]\n",
    "        elif(Y_val[eachIndex]==1):\n",
    "            classLabel=classLabels[1]\n",
    "        else:\n",
    "            classLabel=classLabels[2]\n",
    "        #Then, copy the validation images to the validation folder\n",
    "        shutil.move(base_dir+'/Training/'+classLabel+'/'+X_val[eachIndex],\n",
    "                    base_dir+'/Validation/'+classLabel+'/'+X_val[eachIndex])\n",
    "\n",
    "    picture_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1. / 255,\n",
    "                                           rotation_range=20,\n",
    "                                           shear_range=0.2,\n",
    "                                           zoom_range=0.2,\n",
    "                                           horizontal_flip=True)\n",
    "    \n",
    "    training_set = picture_datagen.flow_from_directory(training_dir,\n",
    "                                                       shuffle=True,\n",
    "                                                       target_size=picture_size,\n",
    "                                                       batch_size=batch_size,\n",
    "                                                       class_mode='categorical')\n",
    "\n",
    "    # Preprocessing the Test set\n",
    "    test_set = picture_datagen.flow_from_directory(validation_dir,\n",
    "                                                   shuffle=True,\n",
    "                                                   target_size=picture_size,\n",
    "                                                   batch_size=batch_size,\n",
    "                                                   class_mode='categorical')\n",
    "\n",
    "\n",
    "    # Training the CNN on the Training set and evaluating it on the Test set\n",
    "    fit = cnn.fit(training_set,\n",
    "                    epochs=epoch,\n",
    "                    validation_data=test_set)\n",
    "    \n",
    "    for i in range(epoch):\n",
    "      history_loss.append(fit.history['loss'][i])\n",
    "      history_acc.append(fit.history['accuracy'][i])\n",
    "      history_val_loss.append(fit.history['val_loss'][i])\n",
    "      history_val_acc.append(fit.history['val_accuracy'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab as pl\n",
    "pl.figure()\n",
    "\n",
    "pl.subplot(121)\n",
    "pl.plot(history_acc)\n",
    "pl.ylim([0,1])\n",
    "pl.title('Accuracy:')\n",
    "pl.plot(history_val_acc)\n",
    "pl.legend(('Train', 'Val'))\n",
    "\n",
    "pl.subplot(122)\n",
    "pl.plot(history_loss)\n",
    "pl.ylim([0,1])\n",
    "pl.title('Loss:')\n",
    "pl.plot(history_val_loss)\n",
    "pl.legend(('Train', 'Val'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qa-MHjHjdWP6"
   },
   "outputs": [],
   "source": [
    "pl.figure()\n",
    "\n",
    "pl.subplot(121)\n",
    "pl.ylim([0,1])\n",
    "pl.plot(history_acc)\n",
    "pl.title('Accuracy train:')\n",
    "\n",
    "pl.subplot(122)\n",
    "pl.ylim([0,1])\n",
    "pl.title('Accuracy Val:')\n",
    "pl.plot(history_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.figure()\n",
    "\n",
    "pl.subplot(121)\n",
    "pl.plot(history_loss)\n",
    "pl.title('Loss Train:')\n",
    "\n",
    "pl.subplot(122)\n",
    "pl.title('Loss Val:')\n",
    "pl.plot(history_val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath = os.path.join(base_dir, filepath)\n",
    "cnn.save(modelpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, confusion_matrix, roc_curve, auc, recall_score\n",
    "import pylab as pl\n",
    "\n",
    "def my_metrics(y_true, y_pred, classes, predictions):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='macro')\n",
    "    recall = recall_score(y_true, y_pred, average=\"macro\")\n",
    "    # f1Score=f1_score(y_true, y_pred, average='weighted')\n",
    "    roc_auc = roc_auc_score(classes, predictions, average='macro', multi_class='ovr')\n",
    "    print(\"Accuracy  : {}\".format(accuracy))\n",
    "    print(\"Precision : {}\".format(precision))\n",
    "    print(\"Recall : {}\".format(recall))\n",
    "    print(\"AUC : {}\".format(roc_auc))\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print(cm)\n",
    "    return accuracy, precision, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# menghitung akurasi dari training data\n",
    "\n",
    "picture_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1. / 255,\n",
    "                                           shear_range=0.2,\n",
    "                                           zoom_range=0.2,\n",
    "                                           horizontal_flip=True)\n",
    "    \n",
    "training_set = picture_datagen.flow_from_directory(test_dir,\n",
    "                                                       shuffle=True,\n",
    "                                                       target_size=picture_size,\n",
    "                                                       batch_size=batch_size,\n",
    "                                                       class_mode='categorical')\n",
    "score = cnn.evaluate(training_set)\n",
    "\n",
    "print('Loss: {:0.2f}%'.format(score[0] * 100))\n",
    "print('Accuracy: {:0.2f}%'.format(score[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# menghitung akurasi dari training data\n",
    "predictions = cnn.predict(training_set, verbose=1)\n",
    "\n",
    "yPredictions = np.argmax(predictions, axis=1)\n",
    "true_classes = training_set.classes\n",
    "classes = []\n",
    "for i in true_classes:\n",
    "    if(i == 0):\n",
    "        classes.append([1,0,0])\n",
    "    elif(i == 1):\n",
    "        classes.append([0,1,0])\n",
    "    else:\n",
    "        classes.append([0,0,1])\n",
    "\n",
    "my_metrics(true_classes, yPredictions, classes, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Covid Detection with mobilenet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
